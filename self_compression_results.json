[
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_1.txt",
    "context_window": 50,
    "original_size": 1720,
    "compressed_size": 23,
    "bpc": 0.107,
    "compression_ratio": 74.7826
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_2.txt",
    "context_window": 50,
    "original_size": 630,
    "compressed_size": 20,
    "bpc": 0.254,
    "compression_ratio": 31.5
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_3.txt",
    "context_window": 50,
    "original_size": 982,
    "compressed_size": 22,
    "bpc": 0.1792,
    "compression_ratio": 44.6364
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_4.txt",
    "context_window": 50,
    "original_size": 756,
    "compressed_size": 18,
    "bpc": 0.1905,
    "compression_ratio": 42.0
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.py.txt",
    "context_window": 50,
    "original_size": 2069,
    "compressed_size": 34,
    "bpc": 0.1315,
    "compression_ratio": 60.8529
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.txt",
    "context_window": 50,
    "original_size": 2054,
    "compressed_size": 29,
    "bpc": 0.113,
    "compression_ratio": 70.8276
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_6.txt",
    "context_window": 50,
    "original_size": 2577,
    "compressed_size": 103,
    "bpc": 0.3198,
    "compression_ratio": 25.0194
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_7.txt",
    "context_window": 50,
    "original_size": 2267,
    "compressed_size": 116,
    "bpc": 0.4094,
    "compression_ratio": 19.5431
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Qwen 2.5-3B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_8.txt",
    "context_window": 50,
    "original_size": 1096,
    "compressed_size": 48,
    "bpc": 0.3504,
    "compression_ratio": 22.8333
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_1.txt",
    "context_window": 50,
    "original_size": 1720,
    "compressed_size": 31,
    "bpc": 0.1442,
    "compression_ratio": 55.4839
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_2.txt",
    "context_window": 50,
    "original_size": 630,
    "compressed_size": 27,
    "bpc": 0.3429,
    "compression_ratio": 23.3333
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_3.txt",
    "context_window": 50,
    "original_size": 982,
    "compressed_size": 35,
    "bpc": 0.2851,
    "compression_ratio": 28.0571
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_4.txt",
    "context_window": 50,
    "original_size": 756,
    "compressed_size": 26,
    "bpc": 0.2751,
    "compression_ratio": 29.0769
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.py.txt",
    "context_window": 50,
    "original_size": 2069,
    "compressed_size": 49,
    "bpc": 0.1895,
    "compression_ratio": 42.2245
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.txt",
    "context_window": 50,
    "original_size": 2054,
    "compressed_size": 42,
    "bpc": 0.1636,
    "compression_ratio": 48.9048
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_6.txt",
    "context_window": 50,
    "original_size": 2577,
    "compressed_size": 106,
    "bpc": 0.3291,
    "compression_ratio": 24.3113
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_7.txt",
    "context_window": 50,
    "original_size": 2267,
    "compressed_size": 136,
    "bpc": 0.4799,
    "compression_ratio": 16.6691
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "LiquidAI 1.2B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--LiquidAI--LFM2.5-1.2B-Base/snapshots/1e601c5c9d33bcc8da794c253243d6b258a4d38b",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_8.txt",
    "context_window": 50,
    "original_size": 1096,
    "compressed_size": 41,
    "bpc": 0.2993,
    "compression_ratio": 26.7317
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_1.txt",
    "context_window": 50,
    "original_size": 1720,
    "compressed_size": 50,
    "bpc": 0.2326,
    "compression_ratio": 34.4
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_2.txt",
    "context_window": 50,
    "original_size": 630,
    "compressed_size": 30,
    "bpc": 0.381,
    "compression_ratio": 21.0
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_3.txt",
    "context_window": 50,
    "original_size": 982,
    "compressed_size": 44,
    "bpc": 0.3585,
    "compression_ratio": 22.3182
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_4.txt",
    "context_window": 50,
    "original_size": 756,
    "compressed_size": 41,
    "bpc": 0.4339,
    "compression_ratio": 18.439
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.py.txt",
    "context_window": 50,
    "original_size": 2069,
    "compressed_size": 65,
    "bpc": 0.2513,
    "compression_ratio": 31.8308
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_5.txt",
    "context_window": 50,
    "original_size": 2054,
    "compressed_size": 58,
    "bpc": 0.2259,
    "compression_ratio": 35.4138
  },
  {
    "generator_model": "Llama 3.2-3B-Instruct",
    "generator_slug": "llama32_3b",
    "compressor_model": "Gemma 3-1B",
    "compressor_path": "/home/alexn/.cache/huggingface/hub/models--google--gemma-3-1b-pt/snapshots/fcf18a2a879aab110ca39f8bffbccd5d49d8eb29",
    "source_file": "/home/alexn/Documents/code/research/LLMzip_from_scratch/source_text/generated_llama32_3b_6.txt",
    "context_window": 50,
    "original_size": 2577,
    "compressed_size": 133,
    "bpc": 0.4129,
    "compression_ratio": 19.3759
  }
]